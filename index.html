
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <title>Scene-Aware Background Music Synthesis, ACM Multimedia 2020, Project Page</title>
    <!--<meta name="google" content="notranslate" />-->
    <meta name="description" content="Background music not only provides auditory experience for users,
    but also conveys, guides, and promotes emotions that resonate with
    visual contents. Studies on how to synthesize background music
    for different scenes can promote research in many fields, such as
    human behaviour research. Although considerable effort has been
    directed toward music synthesis, the synthesis of appropriate music
    based on scene visual content remains an open problem.
    
    In this paper we introduce an interactive background music syn-
    thesis algorithm guided by visual content. We leverage a cascading
    
    strategy to synthesize background music in two stages: Scene Vi-
    sual Analysis and Background Music Synthesis. First, seeking a deep
    
    learning-based solution, we leverage neural networks to analyze
    the sentiment of the input scene. Second, real-time background
    music is synthesized by optimizing a cost function that guides the
    selection and transition of music clips to maximize the emotion
    
    consistency between visual and auditory criteria, and music conti-
    nuity. In our experiments, we demonstrate the proposed approach
    
    can synthesize dynamic background music for different types of
    scenarios. We also conducted quantitative and qualitative analysis
    on the synthesized results of multiple example scenes to validate
    the efficacy of our approach.">
    <link rel="stylesheet" href="./files/dli_proj.css" type="text/css" charset="utf-8" />
    <link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,500" rel="stylesheet">
    <meta name="author" content="Dingzeyu Li" >
    <meta name="author-url" content="http://dingzeyu.li/" >
</head>

<body>

<header>
  Scene-Aware Background Music Synthesis
<div id="authors"><br>
  <a href="https://bitwangyujia.github.io/research/">Yujia Wang</a>,
  <a href="https://liangwei-bit.github.io/web/">Wei Liang</a>,
  <a href="https://wanwanligmu.wixsite.com/mysite">Wanwan Li</a>,
  <a href="http://dingzeyu.li/">Dingzeyu Li</a>,
  <a href="https://craigyuyu.github.io/home/">Lap-Fai Yu</a>,
</div>
<br>
<div id="pub_venue"> ACM Multimedia 2020</div>
<br>
</header>

<div id="main">
<br>


<!--
  <div class="video-container" >
    <iframe width="1280" height="720" src="https://www.youtube.com/embed/AeO4ydc8yqY" frameborder="0" allowfullscreen></iframe> 
  </div>
-->

        
  <br><i><b>abstract</b></i><br>
  <div id="abstract">
    Background music not only provides auditory experience for users, but also conveys, guides, and promotes emotions that resonate with visual contents. Studies on how to synthesize background music for different scenes can promote research in many fields, such as human behaviour research. Although considerable effort has been directed toward music synthesis, the synthesis of appropriate music based on scene visual content remains an open problem.

In this paper we introduce an interactive background music synthesis algorithm guided by visual content. We leverage a cascading strategy to synthesize background music in two stages: Scene Visual Analysis and Background Music Synthesis. First, seeking a deep learning-based solution, we leverage neural networks to analyze the sentiment of the input scene. Second, real-time background music is synthesized by optimizing a cost function that guides the selection and transition of music clips to maximize the emotion consistency between visual and auditory criteria, and music continuity. In our experiments, we demonstrate the proposed approach can synthesize dynamic background music for different types of scenarios. We also conducted quantitative and qualitative analysis on the synthesized results of multiple example scenes to validate the efficacy of our approach.
  </div>
  <hr>

  <div id="downloads_list">
  <i><b>materials</b></i>
  <br>
  <a href="./files/scene-aware-background-music-synthesis-acm-multimedia-2020-wang-et-al.pdf"><abbr title="2MB original resolution">Paper</abbr> </a>   
    <hr>
  <br>

  <i><b>acknowledgements</b></i><br>
  <p>
    The authors are grateful for Adobeâ€™s support in this research. We thank Kelian Li et al. for the help of music generation for different virtual scene navigations.
  </p>

  <hr>
  <br>

  <div id="footer">
    <script type="text/javascript" src="./files/copyright.js"></script>
  </div>
</div>

</body>
</html>

